{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> What to do when the data DataFest gives you isn't enough? </h1>\n",
    "\n",
    "<h2> Find more data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part 1 : Fighting with datasets\n",
    "---------------------------------------------\n",
    "\n",
    "    1. delimiters!\n",
    "    2. character encodings!\n",
    "    3. 200 year old website users (self-reported) :(\n",
    "<script>\n",
    "interested in learning more about how to markdown cells?: http://daringfireball.net/projects/markdown/syntax\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Developing new analyses\n",
    "-----------------------------------------------------\n",
    "    \n",
    "    1. what are some vague areas you want to look into?\n",
    "    2. what datasets exist that might provide grounds for you to test hypotheses?\n",
    "    3. what questions do your datasets suggest to you?\n",
    "\n",
    "    * responses to the above:\n",
    "        * Books!\n",
    "        * http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n",
    "        * exploration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Part 1: Fighting with datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! conda info -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note: New datasets don't always load easily with the tools we used on the baseball dataset. We need to change how we load.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books = pd.read_csv('../data/BX-Books.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Question: what's a 'Traceback' i.e., stacktrace? </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. we can use the information from the stacktrace to infer and fix the root issues in our processes. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/BX-Books.csv', 'rb') as f:\n",
    "    i=0\n",
    "    for l in f.readlines():\n",
    "        print (l)\n",
    "        if i==3:\n",
    "            break\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. adding the correct separator gets us farther, but we still can't load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fails with a CParserError\n",
    "\n",
    "books = pd.read_csv('../data/BX-Books.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question. How impacted will our analyses be if we just throw out the lines we can't read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fails with a UnicodeDecodeError\n",
    "\n",
    "bad_lines = []\n",
    "\n",
    "with open('../data/BX-Books.csv', 'r') as f:\n",
    "    print (f.readline())\n",
    "    for l in f.readlines():\n",
    "        if len(l.split(\";\")) > 8:\n",
    "            bad_lines.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Note. We need to tell python what kind of characters are in our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_lines = []\n",
    "\n",
    "with open('../data/BX-Books.csv', 'r', encoding='ISO-8859-1') as f:\n",
    "    print (f.readline())\n",
    "    for l in f.readlines():\n",
    "        if len(l.split(\";\")) > 8:\n",
    "            bad_lines.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bad_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_lines[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Question. How many records are there total in my dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/BX-Books.csv', 'r', encoding='ISO-8859-1') as f:\n",
    "    total_records = len(f.readlines()) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(len(bad_lines))/total_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note. if you really wanted to fix this problem, you would probably just use unix command line tools:\n",
    ">LC_CTYPE=C && LANG=C && sed 's/\\&amp;/\\&/g' BX-Books.csv > BX-Books_no_semi_colon.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. Okay. Let's just sacrifice some records.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books = pd.read_csv('../data/BX-Books.csv', sep=';', encoding='ISO-8859-1', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books = pd.read_csv('../data/BX-Books.csv', sep=';', encoding='ISO-8859-1', error_bad_lines=False)\n",
    "demo = pd.read_csv('../data/BX-Users.csv', sep=';', encoding='ISO-8859-1')\n",
    "ratings = pd.read_csv('../data/BX-Book-Ratings.csv', sep=';', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"http://imgs.xkcd.com/comics/perl_problems.png \">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Part 2: Developing new analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2.a : Figure out what data you have</h2>\n",
    "\n",
    "<h3> So, now that it's loaded, what's actually in this books dataset? What questions does it suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> What's in the demo table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> What's in the rating table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Part 2.b : Write down some guiding questions\n",
    "<h2>\n",
    "Do people of different ages read books published in different years?\n",
    "<p>\n",
    "Do people of different ages rank the same book differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Question. What does the age distribution look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc=demo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo.describe??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo.describe([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_age(df, col='Age'):\n",
    "    \"\"\"Makes a nice quartiles plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "    col : str\n",
    "        column that you want to plot quartiles for\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.axes\n",
    "        plot object\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(30,30)) # make a nice and large figure\n",
    "    desc=df.describe() # get the data frame description\n",
    "    ax = df[col].dropna().hist(bins=30)\n",
    "    plt.vlines(desc.loc['25%'][col],0,45000, linewidth=5)\n",
    "    plt.vlines(desc.loc['50%'][col],0,45000, linewidth=5)\n",
    "    plt.vlines(desc.loc['75%'][col],0,45000, linewidth=5)\n",
    "    \n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> What does a histogram of ages look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_age(demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. Filter out unreasonable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo2 = demo[demo.Age>10][demo.Age<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_age(demo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "demo2.Age.hist(bins=10)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "demo2.Age.apply(lambda x : np.log(x)).hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. We need to merge our datasets to be able to ask the question \"do people of different ages read books published in different years?\" </h3>\n",
    "\n",
    "<h3> Question. What are the common keys?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note: specify merge key for the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = demo2.merge(ratings, \n",
    "                 left_on='User-ID', \n",
    "                 right_on='User-ID')\n",
    "\n",
    "all_dat = df.merge(books, \n",
    "                   left_on='ISBN', \n",
    "                   right_on='ISBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. we can now build some age-related binned categorical variables and make some box plots comparing different age quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.qcut??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels=['young','young-mid','mid','mid-old','old']\n",
    "\n",
    "all_dat['age_bins'] = pd.qcut(all_dat.Age, 5, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note. let's summarize our data by categorical age variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print (np.mean(all_dat[all_dat.age_bins=='young'].Age))\n",
    "print (np.mean(all_dat[all_dat.age_bins=='young-mid'].Age))\n",
    "print (np.mean(all_dat[all_dat.age_bins=='mid'].Age))\n",
    "print (np.mean(all_dat[all_dat.age_bins=='mid-old'].Age))\n",
    "print (np.mean(all_dat[all_dat.age_bins=='old'].Age))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_dat.groupby??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://nbviewer.jupyter.org/github/jkthompson/pyspark-pictures/blob/master/images/pyspark-page18.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dat.groupby('age_bins').Age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. Not free from our data woes yet ... we ended up putting a string field in a year column ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Failes with DataError\n",
    "\n",
    "all_dat.groupby('age_bins')['Year-Of-Publication'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. let's do a forcible type conversion and see if we get any more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fails with ValueError\n",
    "\n",
    "all_dat['Year-Of-Publication'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cast(val):\n",
    "    try:\n",
    "        return int(val)\n",
    "    except ValueError as e:\n",
    "        print (e, val)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dat['Year-Of-Publication'] = all_dat['Year-Of-Publication'].apply(lambda x : cast(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dat.groupby('age_bins')['Year-Of-Publication'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dat.groupby('age_bins')['Year-Of-Publication'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_dat.boxplot(column='Year-Of-Publication', by='age_bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. No effect of age on publication date of reading material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Question. Do people of different ages rank the same book differently?</h2>\n",
    "\n",
    "* Basically, for each book, we want an average of how each age group ranked it (use groupby for that) -- then we need some way to measure how similarly the various groups ranked books ... correlation matrix?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gall_dat = all_dat.groupby(['ISBN','age_bins'])['Book-Rating'].mean()\n",
    "gall_dat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(gall_dat).reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.pivot??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivot_df = pd.DataFrame(gall_dat).reset_index().pivot('age_bins',columns='ISBN',values='Book-Rating')\n",
    "pivot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pivot_df.T.dropna()), len(pivot_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.corr??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr=pivot_df.T.dropna().corr()\n",
    "\n",
    "corr.reindex(labels)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "df=np.fill_diagonal(corr.values, 0)\n",
    "sm.graphics.plot_corr(corr, xnames=labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Note. maybe some age-bin structure in how pairs of bins rank books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " all_dat.groupby(['ISBN','age_bins'])['Book-Rating'].size().hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Question. Maybe different age groups rank the same authors differently? Maybe grouping by author instead of book would give us more interesting results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gall_dat = all_dat.groupby(['Book-Author','age_bins'])['Book-Rating'].mean()\n",
    "\n",
    "gall_dat.head()\n",
    "pivot_df = pd.DataFrame(gall_dat).reset_index().pivot('age_bins',columns='Book-Author',values='Book-Rating')\n",
    "pivot_df.head()\n",
    "\n",
    "len(pivot_df.T.dropna()), len(pivot_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "corr=pivot_df.T.dropna().corr()\n",
    "corr.reindex(labels)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=np.fill_diagonal(corr.values, 0)\n",
    "sm.graphics.plot_corr(corr, xnames=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Question. Another view of the question about whether different age bins view the same books differently: do authors make up different percentages of the reading lists of typical people in each age bin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_dat.groupby('Book-Author').size().sort(inplace=False, ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(np.sum([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def t_val(val, series):\n",
    "    \"\"\" t-value of val wrt series\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    val : int\n",
    "    series : `pd.Series` or list of ints\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float \n",
    "        t-value of input `val` relative to input `series`\n",
    "    \"\"\"\n",
    "    return (val - np.mean(series))/float(np.std(series))\n",
    "\n",
    "\n",
    "def percentage(val, series):\n",
    "    \"\"\"percentage of series represented by val\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    val : int\n",
    "    series : `pd.Series` or list of ints\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float \n",
    "        percentage of input `val` represents relative to sum of vals in `series`\n",
    "    \"\"\"\n",
    "    \n",
    "    return (val / float(np.sum(series)))\n",
    "\n",
    "\n",
    "def author_ranker(author, rank_function):\n",
    "    \"\"\"applies input ranking function for author to all age_bins in df\"\"\"\n",
    "    \n",
    "    for age_bin, grouped in all_dat.groupby('age_bins'): # iterate on your groups\n",
    "        sizes=grouped.groupby('Book-Author').size() # run on a new groupby on the grouped items\n",
    "        yield {'age_bin': age_bin, author:rank_function(sizes[author], sizes)} # generator magic ... you can also just \n",
    "                                                                               # list.append\n",
    "    \n",
    "    \n",
    "def author_plotter(author, rank_function):\n",
    "    \"\"\"builds a plot for author rank across all age_bins in df\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    author : str\n",
    "    rank_function : types.FunctionType\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.axes\n",
    "        a matplotlib plot\n",
    "    \"\"\"\n",
    "    \n",
    "    author_rankings = author_ranker(author, rank_function)\n",
    "    df = pd.DataFrame(author_rankings).set_index('age_bin') # this is great, gives us rank for each author\n",
    "    df = df.reindex(age_bins) # but age bins are out of order, so re-order\n",
    "    \n",
    "    ax = df[author].plot(legend=True) # now plot the author\n",
    "    plt.title(rank_function.__name__) # add a title by 'looking inside' the function you passed in\n",
    "    plt.ylabel(rank_function.__name__)\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "    \n",
    "    \n",
    "authors=['Stephen King', 'James Patterson', 'Mary Higgins Clark', 'J. K. Rowling', 'Danielle Steel']\n",
    "\"\"\"list: a set of authors we want to run stats on\"\"\"\n",
    "\n",
    "age_bins = ['young', 'young-mid', 'mid', 'mid-old', 'old']\n",
    "\"\"\"list: the age bins represented in our value datafame\"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    for author in authors:\n",
    "        author_plotter(author, t_val)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for author in authors:\n",
    "        author_plotter(author, percentage)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,30))\n",
    "all_dat.groupby('Book-Author').size().sort(inplace=False, ascending=False).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
